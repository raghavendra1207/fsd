{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CXT_IBNgKihG"
      },
      "outputs": [],
      "source": [
        "#1a)\n",
        "import pandas as pd\n",
        "url='C:/Users/MRCET1/Desktop/train.csv'\n",
        "df=pd.read_csv(url)\n",
        "df.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#1b)\n",
        "import pandas as pd\n",
        "marks_data=pd.DataFrame({'ID':{0:23,1:43,2:12,3:13,4:67,5:89},'NAME':{0:'Ram',1:'Deep',2:'Yash',3:'Arjun',4:'Aditya',5:'Divya'},'Marks':{0:89,1:92,2:45,3:78,4:56,5:76},'Grade':{0:'b',1:'a',2:'f',3:' c',4:'e',5:'c'}})\n",
        "filename='C:/Users/MRCET1/Desktop/Marksdata.xlsx'\n",
        "marks_data.to_excel(filename)\n",
        "print('Data frame written to Excel')"
      ],
      "metadata": {
        "id": "8HzldTeyk-G8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#2a)\n",
        "#K-MEANS CLUSTERING ALGORITHM#\n",
        "# ----------installations---------------\n",
        "# 1.pip install scikit-learn\n",
        "# 2.pip install matplotlib\n",
        "# 3.pip install k-means-constrained\n",
        "# 4.pip install pandas\n",
        "from sklearn.datasets import make_blobs\n",
        "import matplotlib.pyplot as plt\n",
        "from k_means_constrained import KMeansConstrained\n",
        "import pandas as pd\n",
        "df = pd.read_csv('student_clustering.csv')\n",
        "X = df.iloc[:, :].values\n",
        "km = KMeansConstrained(n_clusters=4, max_iter=500)\n",
        "y_means = km.fit_predict(X)\n",
        "plt.scatter(X[y_means == 0, 0], X[y_means == 0, 1], color='red')\n",
        "plt.scatter(X[y_means == 1, 0], X[y_means == 1, 1], color='blue')\n",
        "plt.scatter(X[y_means == 2, 0], X[y_means == 2, 1], color='green')\n",
        "plt.scatter(X[y_means == 3, 0], X[y_means == 3, 1], color='yellow')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "t-rJEmtZk60m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#2b)\n",
        "#Logistic Regression#\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "x = np.arange(10).reshape(-1, 1)\n",
        "y = np.array([0, 0, 0, 0, 1, 1, 1, 1, 1, 1])\n",
        "x\n",
        "y\n",
        "model = LogisticRegression(solver='liblinear', random_state=0)\n",
        "model.fit(x, y)\n",
        "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,intercept_scaling=1, l1_ratio=None, max_iter=100,multi_class='warn', n_jobs=None, penalty='l2',random_state=0, solver='liblinear', tol=0.0001, verbose=0,warm_start=False)\n",
        "model = LogisticRegression(solver='liblinear', random_state=0).fit(x, y)\n",
        "model.classes_\n",
        "model.intercept_\n",
        "model.coef_\n",
        "model.predict_proba(x)"
      ],
      "metadata": {
        "id": "1NGj4nAOh9gl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#3a)\n",
        "import pandas,numpy\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "df=pandas.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv',sep=';')\n",
        "array=df.values\n",
        "x=array[:,0:8]\n",
        "y=array[:,8]\n",
        "scaler=MinMaxScaler(feature_range=(0,1))\n",
        "rescaledX=scaler.fit_transform(x)\n",
        "numpy.set_printoptions(precision=2)\n",
        "print(\"OUTPUT\")\n",
        "rescaledX[0:2,:]"
      ],
      "metadata": {
        "id": "5OnLNrqAjE1x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#3b)Standardizing Data\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler=StandardScaler().fit(x)\n",
        "rescaledX=scaler.transform(x)\n",
        "print(\"OUTPUT\")\n",
        "rescaledX[0:2,:]"
      ],
      "metadata": {
        "id": "TZmjK13lkPSE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#3)c.Normalizing Data\n",
        "from sklearn.preprocessing import Normalizer\n",
        "scaler=Normalizer().fit(x)\n",
        "normalized=scaler.transform(x)\n",
        "print(\"OUTPUT\")\n",
        "normalized[0:2,:]"
      ],
      "metadata": {
        "id": "vhkm9a9Fkng6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#9)a.Binarizing Data\n",
        "from sklearn.preprocessing import Binarizer\n",
        "binarizer=Binarizer().fit(x)\n",
        "binarized=binarizer.transform(x)\n",
        "print(\"OUTPUT\")\n",
        "binarized[0:2,:]"
      ],
      "metadata": {
        "id": "tJBMLPr3GSjA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#9)b.Mean Removal\n",
        "from sklearn.preprocessing import scale\n",
        "data_standardized=scale(df)\n",
        "data_standardized.mean(axis=0)\n",
        "print('OUTPUT')\n",
        "data_standardized.std(axis=0)"
      ],
      "metadata": {
        "id": "SliFsnyYHMri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZozI9vbIHlZz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#4)\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "# Function importing Dataset\n",
        "def importdata():\n",
        "  balance_data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-'+'databases/balance-scale/balance-scale.data',sep= ',', header = None)\n",
        "  # Printing the dataswet shape\n",
        "  print (\"Dataset Length: \", len(balance_data))\n",
        "  print (\"Dataset Shape: \", balance_data.shape)\n",
        "  # Printing the dataset obseravtions\n",
        "  print (\"Dataset: \",balance_data.head())\n",
        "  return balance_data\n",
        "# Function to split the dataset\n",
        "def splitdataset(balance_data):\n",
        "  # Separating the target variable\n",
        "  X = balance_data.values[:, 1:5]\n",
        "  Y = balance_data.values[:, 0]\n",
        "  # Splitting the dataset into train and test\n",
        "  X_train, X_test, y_train, y_test = train_test_split(\n",
        "  X, Y, test_size = 0.3, random_state = 100)\n",
        "  return X, Y, X_train, X_test, y_train, y_test\n",
        "# Function to perform training with giniIndex.\n",
        "def train_using_gini(X_train, X_test, y_train):\n",
        "  # Creating the classifier object\n",
        "  clf_gini = DecisionTreeClassifier(criterion = \"gini\",\n",
        "  random_state = 100,max_depth=3, min_samples_leaf=5)\n",
        "  # Performing training\n",
        "  clf_gini.fit(X_train, y_train)\n",
        "  return clf_gini\n",
        "# Function to perform training with entropy.\n",
        "def tarin_using_entropy(X_train, X_test, y_train):\n",
        "  # Decision tree with entropy\n",
        "  clf_entropy = DecisionTreeClassifier(\n",
        "  criterion = \"entropy\", random_state = 100,\n",
        "  max_depth = 3, min_samples_leaf = 5)\n",
        "  # Performing training\n",
        "  clf_entropy.fit(X_train, y_train)\n",
        "  return clf_entropy\n",
        "# Function to make predictions\n",
        "def prediction(X_test, clf_object):\n",
        "  # Predicton on test with giniIndex\n",
        "  y_pred = clf_object.predict(X_test)\n",
        "  print(\"Predicted values:\")\n",
        "  print(y_pred)\n",
        "  return y_pred\n",
        "# Function to calculate accuracy\n",
        "def cal_accuracy(y_test, y_pred):\n",
        "  print(\"Confusion Matrix: \",\n",
        "  confusion_matrix(y_test, y_pred))\n",
        "  print (\"Accuracy : \",\n",
        "  accuracy_score(y_test,y_pred)*100)\n",
        "  print(\"Report : \",\n",
        "  classification_report(y_test, y_pred))\n",
        "# Driver code\n",
        "def main():\n",
        "# Building Phase\n",
        "  data = importdata()\n",
        "  X, Y, X_train, X_test, y_train, y_test = splitdataset(data)\n",
        "  clf_gini = train_using_gini(X_train, X_test, y_train)\n",
        "  clf_entropy = tarin_using_entropy(X_train, X_test, y_train)\n",
        "  # Operational Phase\n",
        "  print(\"Results Using Gini Index:\")\n",
        "  # Prediction using gini\n",
        "  y_pred_gini = prediction(X_test, clf_gini)\n",
        "  cal_accuracy(y_test, y_pred_gini)\n",
        "  print(\"Results Using Entropy:\")\n",
        "  # Prediction using entropy\n",
        "  y_pred_entropy = prediction(X_test, clf_entropy)\n",
        "  cal_accuracy(y_test, y_pred_entropy)\n",
        "# Calling main function\n",
        "if __name__==\"__main__\":\n",
        "  main()"
      ],
      "metadata": {
        "id": "W4mlcLfJRp03"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#5a)\n",
        "#NAVIE BAYES CLASSIFICATION#\n",
        "import pandas as pd\n",
        "dataset = pd.read_csv('C:/Users/MRCET1/Desktop/train.csv')\n",
        "X = dataset.iloc[:, [2, 3]].values\n",
        "y = dataset.iloc[:, -1].values\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20,random_state = 0)\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "classifier = GaussianNB()\n",
        "classifier.fit(X_train, y_train)\n",
        "y_pred = classifier.predict(X_test)\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "ac = accuracy_score(y_test,y_pred)\n",
        "cm = confusion_matrix(y_test, y_pred)\n"
      ],
      "metadata": {
        "id": "uXIkiBLvWTZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#5b)KNN CLASSIFICATION MODEL#\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "df = pd.read_csv('C:/Users/MRCET1/Desktop/train.csv')\n",
        "y = df['diagnosis']\n",
        "X = df.drop('diagnosis', axis=1)\n",
        "X = X.drop('Unnamed: 32', axis=1)\n",
        "X = X.drop('id', axis=1)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
        "K = []\n",
        "training = []\n",
        "test = []\n",
        "scores = {}\n",
        "for k in range(2, 21):\n",
        " clf = KNeighborsClassifier(n_neighbors=k)\n",
        " clf.fit(X_train, y_train)\n",
        " training_score = clf.score(X_train, y_train)\n",
        " test_score = clf.score(X_test, y_test)\n",
        " K.append(k)\n",
        " training.append(training_score)\n",
        " test.append(test_score)\n",
        " scores[k] = [training_score, test_score]\n",
        "ax = sns.stripplot(training)\n",
        "ax.set(xlabel='values of k', ylabel='Training Score')\n",
        "plt.show()\n",
        "ax = sns.stripplot(test)\n",
        "ax.set(xlabel='values of k', ylabel='Test Score')\n",
        "plt.show()\n",
        "plt.scatter(K, training, color='k')\n",
        "plt.scatter(K, test, color='g')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "djiGG-6zmeTJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import preprocessing\n",
        "import seaborn as sns\n",
        "csv_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'\n",
        "col=['Sepal_Length','Sepal_Width','Petal_Length','Petal_Width','Class']\n",
        "iris=pd.read_csv(csv_url,names=col)\n",
        "iris.head()\n"
      ],
      "metadata": {
        "id": "t_hZl4cHkdPJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#6b)\n",
        "a=iris['Class'].value_counts()\n",
        "species=a.index\n",
        "count=a.values\n",
        "plt.bar(species,count,color='lightblue')\n",
        "plt.xlabel('species')\n",
        "plt.ylabel('count')\n",
        "plt.title('Bar Graph')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "axGkkOMwqZ33"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#8b)\n",
        "import numpy as np\n",
        "data_ = np.random.randn(1000)\n",
        "plt.hist(data_,bins = 40,color='gold')\n",
        "plt.grid(True)\n",
        "plt.xlabel('points')\n",
        "plt.title('Histogram')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ttIQiPh-FAjq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Creating dataset\n",
        "cars = ['AUDI', 'BMW', 'FORD',\n",
        "\t\t'TESLA', 'JAGUAR', 'MERCEDES']\n",
        "\n",
        "data = [23, 17, 35, 29, 12, 41]\n",
        "\n",
        "# Creating plot\n",
        "fig = plt.figure(figsize =(10, 7))\n",
        "plt.pie(data, labels = cars)\n",
        "\n",
        "# show plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "kDViaZtbI2lk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#8a)LINE PLOT\n",
        "import numpy as np\n",
        "x=np.linspace(0,20,30)\n",
        "y=x**2\n",
        "plt.plot(x,y)\n",
        "plt.xlabel('x-values')\n",
        "plt.ylabel('x^2-values')\n",
        "plt.title('line plot')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NJgKDcSJnlNO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#7a)1)#SIMPLE LINEAR REGRESSION#\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "def estimate_coef(x, y):\n",
        "  n = np.size(x)\n",
        "  m_x = np.mean(x)\n",
        "  m_y = np.mean(y)\n",
        "  SS_xy = np.sum(y*x) - n*m_y*m_x\n",
        "  SS_xx = np.sum(x*x) - n*m_x*m_x\n",
        "  b_1 = SS_xy / SS_xx\n",
        "  b_0 = m_y - b_1*m_x\n",
        "  return (b_0, b_1)\n",
        "def plot_regression_line(x, y, b):\n",
        "  plt.scatter(x, y, color = \"m\",marker = \"o\", s = 30)\n",
        "  y_pred = b[0] + b[1]*x\n",
        "  plt.plot(x, y_pred, color = \"g\")\n",
        "  plt.xlabel('x')\n",
        "  plt.ylabel('y')\n",
        "  plt.show()\n",
        "def main():\n",
        "  x = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
        "  y = np.array([1, 3, 2, 5, 7, 8, 8, 9, 10, 12])\n",
        "  b = estimate_coef(x, y)\n",
        "  print(\"Estimated coefficients:\\nb_0 = {} \\\\nb_1 = {}\".format(b[0], b[1]))\n",
        "  plot_regression_line(x, y, b)\n",
        "if __name__ == \"__main__\":\n",
        "  main()\n"
      ],
      "metadata": {
        "id": "gX5TCxysoZRP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#7b)#MULTIPLE LINEAR REGRESSION#\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "def estimate_coef(x, y):\n",
        "  n = np.size(x)\n",
        "  m_x = np.mean(x)\n",
        "  m_y = np.mean(y)\n",
        "  SS_xy = np.sum(y*x) - n*m_y*m_x\n",
        "\n",
        "  SS_xx = np.sum(x*x) - n*m_x*m_x\n",
        "  b_1 = SS_xy / SS_xx\n",
        "  b_0 = m_y - b_1*m_x\n",
        "  return (b_0, b_1)\n",
        "def plot_regression_line(x, y, b):\n",
        "  plt.scatter(x, y, color = \"m\",\n",
        "  marker = \"o\", s = 30)\n",
        "  y_pred = b[0] + b[1]*x\n",
        "  plt.plot(x, y_pred, color = \"g\")\n",
        "  plt.xlabel('x')\n",
        "  plt.ylabel('y')\n",
        "  plt.show()\n",
        "def main():\n",
        "  x = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
        "  y = np.array([1, 3, 2, 5, 7, 8, 8, 9, 10, 12])\n",
        "  b = estimate_coef(x, y)\n",
        "  print(\"Estimated coefficients:\\nb_0 = {} \\\\nb_1 = {}\".format(b[0], b[1]))\n",
        "  plot_regression_line(x, y, b)\n",
        "if __name__ == \"__main__\":\n",
        "  main()"
      ],
      "metadata": {
        "id": "1C5phUS3qBuL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#6a)\n",
        "length_width = iris[['Petal_Length','Petal_Width','Sepal_Length','Sepal_Width']]\n",
        "length_width.boxplot()\n",
        "plt.xlabel('Flower measurements')\n",
        "plt.ylabel('values')\n",
        "plt.title(\"Iris dataset analysis\")\n"
      ],
      "metadata": {
        "id": "r4lkF08yswrz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#6c)SCATTER PLOT\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "iris = load_iris()\n",
        "df= pd.DataFrame(data= np.c_[iris['data'], iris['target']],columns= iris['feature_names'] + ['target'])\n",
        "y = df.iloc[0:100, 4].values\n",
        "y = np.where(y == 'Iris-setosa', 0, 1)\n",
        "X = df.iloc[0:100, [0, 2]].values\n",
        "plt.scatter(X[:50, 0], X[:50, 1],color='blue', marker='o', label='Setosa')\n",
        "plt.scatter(X[50:100, 0], X[50:100, 1],color='green', marker='s', label='Versicolor')\n",
        "plt.xlabel('Sepal length [cm]')\n",
        "plt.ylabel('Petal length [cm]')\n",
        "plt.legend(loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "edHc0AmIttT_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V_yNL8w5DJS4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}